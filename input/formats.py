from event import EventBroadcaster, ProgressEvent
from input.interfaces import Tokenizer
from util.cache import CacheMixin

from input.interfaces import CorpusParser, SamplePair
import os
import random
from typing import Callable, Iterable, List
import xml.etree.ElementTree as etree


class BookSampleParser(CorpusParser):
    """
    Parser for book samples. Expects a directory structure where there is one folder
    for each author containing at least two samples of their work.
    Example::

        + Ernest_Hemingway
        |__ + The_Torrents_of_Spring.txt
        |__ + Islands_in_the_Stream.txt
        |__ + The_Garden_of_Eden.txt
        + William_Faulkner
        |__ + Soldier's_Pay.txt
        |__ + Light_in_August.txt

    File and folder names can be chosen arbitrarily, but the book sample files must end in .txt.
    Pairs will be generated by matching each text against every other text.
    
    Events published by this class:
    
    * `onProgress`: [type: ProgressEvent]
                    fired during author pair generation to indicate current progress
    
    """

    class Class(SamplePair.Class):
        UNSPECIFIED = -1
        DIFFERENT_AUTHORS = 0
        SAME_AUTHOR = 1
    
    class BookSampleParserIterator:
        def __init__(self, parser):
            self._parser = parser
            
            # file -> author
            self._files = {}
            self._iterator1 = None
            self._next1 = None
            self._current_file_contents = None
            
            # author -> files
            self._authors = {}
            self._iterator2 = None
            self._next2 = None
            
            # de-duplication of single-text pairs
            self._single_text_pairs = []
            
            # read in all directory and file names and build
            # file -> author and author -> files maps
            dirs = os.listdir(self._parser.corpus_path)
            for d in dirs:
                dir_path = os.path.join(self._parser.corpus_path, d)
                if not os.path.isdir(dir_path):
                    continue
                
                files = sorted(os.listdir(dir_path))
                self._authors[d] = []
                for f in files:
                    file_path = os.path.realpath(os.path.join(dir_path, f))
                    if not os.path.isfile(file_path) or not f.endswith(".txt"):
                        continue
                    self._files[file_path] = d
                    self._authors[d].append(file_path)
            
            self._iterator1 = iter(self._files)
            
            # progress publisher
            self._progress_event = ProgressEvent(len(self._files))
        
        def __next__(self) -> SamplePair:
            # next text
            if self._next2 is None:
                EventBroadcaster.publish("onProgress", self._progress_event, self._parser.__class__)
                self._next1 = next(self._iterator1)
                self._iterator2 = iter(self._authors)
                self._progress_event.increment()
                with open(self._next1, "r") as handle:
                    self._current_file_contents = handle.read()
            
            # next author
            try:
                self._next2 = next(self._iterator2)
            except StopIteration:
                self._next2 = None
                return self.__next__()
            
            compare_texts = []
            last_filename = None
            for file_name in self._authors[self._next2]:
                if file_name == self._next1:
                    # don't compare a text with itself
                    continue
                
                with open(file_name, "r") as handle:
                    compare_texts.append(handle.read())
                    last_filename = file_name
            
            num_comp_texts = len(compare_texts)
            if num_comp_texts == 0:
                # if there is only one text of this author, we can't build a pair
                return self.__next__()
            elif num_comp_texts == 1:
                # make sure we don't have the same pair of single texts twice
                pair_set = {self._next1, last_filename}
                if pair_set in self._single_text_pairs:
                    return self.__next__()
                self._single_text_pairs.append(pair_set)
            
            cls = self._parser.Class.DIFFERENT_AUTHORS
            if self._files[self._next1] == self._next2:
                cls = self._parser.Class.SAME_AUTHOR
            
            return SamplePair([self._current_file_contents], compare_texts, cls, self._parser.chunk_tokenizer)
    
    def __iter__(self) -> BookSampleParserIterator:
        return self.BookSampleParserIterator(self)


class BuzzFeedXMLCorpusParser(CorpusParser):
    """
    Corpus parser for the Webis BuzzFeed XML corpus.
    Pairs or generated by randomly drawing 100 texts from the input set without replacement.
    
    Events published by this class:
    
    * `onProgress`: [type: ProgressEvent]
                    fired during author pair generation to indicate current progress
    """
    
    class PairClass(SamplePair.Class):
        UNSPECIFIED = -1
        LEFT_LEFT = 0
        RIGHT_RIGHT = 1
        MAINSTREAM_MAINSTREAM = 2
        LEFT_RIGHT = 3
        LEFT_MAINSTREAM = 4
        RIGHT_MAINSTREAM = 5
    
    class SingleTextClass(SamplePair.Class):
        UNSPECIFIED = -1
        LEFT = 0
        RIGHT = 1
        MAINSTREAM = 2
    
    def __init__(self, corpus_path: str, chunk_tokenizer: Tokenizer, datasets: List[str],
                 class_assigner: Callable[[etree.Element], SingleTextClass]):
        """
        :param datasets: datasets within the corpus to parse
        :param class_assigner: callable object to assign proper class to a document
                               (provided pre-defined methods: :method:`class_by_orientation()`)
        """
        super().__init__(corpus_path, chunk_tokenizer)
        self._datasets = datasets
        self._class_assigner = class_assigner
    
    @staticmethod
    def class_by_orientation(xmlroot: etree.Element) -> SingleTextClass:
        """
        Assign class to pair based on orientation. Assigns classes LEFT, RIGHT or MAINSTREAM.
        Class will be UNSPECIFIED when texts don't match any of these classes.
        Use a reference to this method as parameter for the constructor.
        
        :param xmlroot: XML root of the text
        :return: assigned class
        """
        cls = None
        
        for c in xmlroot:
            if c.tag == "orientation":
                cls = c.text
                break
        
        e = BuzzFeedXMLCorpusParser.SingleTextClass
        if cls == "left":
            return e.LEFT
        elif cls == "right":
            return e.RIGHT
        elif cls == "mainstream":
            return e.MAINSTREAM
        
        return e.UNSPECIFIED
        
    def __iter__(self) -> Iterable[SamplePair]:
        texts_by_class = {}
        for ds in self._datasets:
            ds_path = os.path.join(self.corpus_path, ds)
            files = os.listdir(ds_path)
            for f in files:
                file_path = os.path.join(ds_path, f)
                if not os.path.isfile(file_path) or not f.endswith(".xml"):
                    continue
                
                xml = etree.parse(file_path).getroot()
                cls = self._class_assigner(xml)
                if cls == self.SingleTextClass.UNSPECIFIED:
                    continue
                
                if cls not in texts_by_class:
                    texts_by_class[cls] = []
                texts_by_class[cls].append(xml)
        
        processed_comp_classes = []
        for cls1 in texts_by_class:
            num_texts1 = len(texts_by_class[cls1])
            
            for cls2 in texts_by_class:
                comp_class = {cls1, cls2}
                if comp_class in processed_comp_classes:
                    continue
                processed_comp_classes.append(comp_class)
                
                num_texts2 = len(texts_by_class[cls2])
                
                # list to keep track of already drawn texts, so we don't use them again
                drawn1 = []
                drawn2 = []
                
                # number of already matched chunks / texts
                chunk_counter = 0
                
                # final chunks of a pair
                chunks_a = []
                chunks_b = []
                
                while chunk_counter < 100 and len(drawn1) < num_texts1 and len(drawn2) < num_texts2 > 0:
                    idx1 = random.randint(0, num_texts1 - 1)
                    idx2 = random.randint(0, num_texts2 - 1)
                    if cls1 == cls2:
                        # make sure the cut between both sets is always empty
                        # when comparing a class against itself
                        if idx1 == idx2:
                            continue
                        if idx1 in drawn1 or idx1 in drawn2:
                            continue
                        if idx2 in drawn1 or idx2 in drawn2:
                            continue
                    
                    if idx1 in drawn1 or idx2 in drawn2:
                        continue
                    
                    for c in texts_by_class[cls1][idx1]:
                        if c.tag == "mainText":
                            chunks_a.append(str(c.text))
                            break
                    drawn1.append(idx1)
                    for c in texts_by_class[cls2][idx2]:
                        if c.tag == "mainText":
                            chunks_b.append(str(c.text))
                            break
                    drawn2.append(idx2)
                    
                    chunk_counter += 1
                
                try:
                    pair_class = self.PairClass[str(cls1) + "_" + str(cls2)]
                except KeyError:
                    pair_class = self.PairClass[str(cls2) + "_" + str(cls1)]
                
                yield SamplePair(chunks_a, chunks_b, pair_class, self.chunk_tokenizer)
